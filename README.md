# Analysis of Generative AI Misuse in IT Security

This project investigates the misuse of generative artificial intelligence (GenAI) in cybersecurity, focusing on concrete attack techniques such as prompt injection, AI-supported phishing, social engineering, AI-assisted malware, deepfakes, identity misuse, and automated reconnaissance.

The primary goal is to:
- Identify central vulnerabilities in modern GenAI systems.
- Analyze relevant attack vectors.
- Evaluate technical countermeasures with the aim of strengthening an organization's security in an AI-driven threat model.

## Project Website
For a more detailed overview and practical demonstrations, visit the project website:
https://sin9ularity1.github.io/Valgfag-Generative-AI-Misbrug/index.html

## Key Focus Areas:
- AI-generated phishing
- Social engineering using AI
- AI-assisted malware
- Prompt injection and manipulation
- Deepfakes and identity misuse
- Automated reconnaissance

## Methodology:
The project combines literature study (including OWASP Top 10 for Large Language Models), technical analysis, and selected practical demonstrations. The focus is on understanding concrete attack techniques and evaluating defensive strategies against the misuse of GenAI.

## Learnings:
Through hands-on experiments and in-depth analysis, this project provides insights into the practical mechanisms of AI-driven cyberattacks and discusses broader implications for IT security.

## About the Author:
This project is conducted by Reuben Badham, an IT Security student with an interest in cyber and AI.
